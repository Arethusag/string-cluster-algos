{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|client_id|     full_name|\n",
      "+---------+--------------+\n",
      "|        0|     Smith Bob|\n",
      "|        1|   Jones David|\n",
      "|        2|   Brown Grace|\n",
      "|        3|   Brown Frank|\n",
      "|        4|  Miller David|\n",
      "|        5|Miller Charlie|\n",
      "|        6|Williams Henry|\n",
      "|        7|   Brown Grace|\n",
      "|        8|   Smith Emily|\n",
      "|        9|   Smith Emily|\n",
      "+---------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MattM\\anaconda3\\lib\\site-packages\\pyspark\\sql\\column.py:458: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand, col, array, concat_ws, lit, monotonically_increasing_id\n",
    "\n",
    "num_rows = 1000\n",
    "first_names = [\"John\", \"Jane\", \"Alice\", \"Bob\", \"Charlie\", \"David\", \"Emily\", \"Frank\", \"Grace\", \"Henry\"]\n",
    "last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Jones\", \"Brown\", \"Davis\", \"Miller\", \"Wilson\", \"Moore\", \"Taylor\"]\n",
    "\n",
    "df = spark.range(num_rows)\\\n",
    "  .withColumn(\"client_id\", monotonically_increasing_id())\\\n",
    "  .withColumn(\"first_name\", array(*[lit(name) for name in first_names]).getItem((rand()*10).cast(\"int\")))\\\n",
    "  .withColumn(\"last_name\", array(*[lit(name) for name in last_names]).getItem((rand()*10).cast(\"int\")))\\\n",
    "  .withColumn(\"full_name\", concat_ws(\" \", col(\"last_name\"), col(\"first_name\")))\\\n",
    "  .select(col(\"client_id\"),col(\"full_name\"))\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------------+\n",
      "|client_id|     full_name|  fname_tokenized|\n",
      "+---------+--------------+-----------------+\n",
      "|        0|     Smith Bob|     [smith, bob]|\n",
      "|        1|   Jones David|   [jones, david]|\n",
      "|        2|   Brown Grace|   [brown, grace]|\n",
      "|        3|   Brown Frank|   [brown, frank]|\n",
      "|        4|  Miller David|  [miller, david]|\n",
      "|        5|Miller Charlie|[miller, charlie]|\n",
      "|        6|Williams Henry|[williams, henry]|\n",
      "|        7|   Brown Grace|   [brown, grace]|\n",
      "|        8|   Smith Emily|   [smith, emily]|\n",
      "|        9|   Smith Emily|   [smith, emily]|\n",
      "|       10|   Brown Alice|   [brown, alice]|\n",
      "|       11|  Wilson Grace|  [wilson, grace]|\n",
      "|       12| Johnson Frank| [johnson, frank]|\n",
      "|       13|  Miller Henry|  [miller, henry]|\n",
      "|       14|   Moore Frank|   [moore, frank]|\n",
      "|       15|Williams Grace|[williams, grace]|\n",
      "|       16| Jones Charlie| [jones, charlie]|\n",
      "|       17|   Davis Henry|   [davis, henry]|\n",
      "|       18| Moore Charlie| [moore, charlie]|\n",
      "|       19|Williams David|[williams, david]|\n",
      "+---------+--------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import Normalizer, VectorAssembler\n",
    "\n",
    "\n",
    "# Tokenize the text column\n",
    "tokenizer = Tokenizer(inputCol=\"full_name\", outputCol=\"fname_tokenized\")\n",
    "words_df = tokenizer.transform(df)\n",
    "\n",
    "words_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------------+--------------------+\n",
      "|client_id|     full_name|  fname_tokenized|      fname_features|\n",
      "+---------+--------------+-----------------+--------------------+\n",
      "|        0|     Smith Bob|     [smith, bob]|(20,[9,13],[1.0,1...|\n",
      "|        1|   Jones David|   [jones, david]|(20,[0,8],[1.0,1.0])|\n",
      "|        2|   Brown Grace|   [brown, grace]|(20,[6,17],[1.0,1...|\n",
      "|        3|   Brown Frank|   [brown, frank]|(20,[1,6],[1.0,1.0])|\n",
      "|        4|  Miller David|  [miller, david]|(20,[5,8],[1.0,1.0])|\n",
      "|        5|Miller Charlie|[miller, charlie]|(20,[4,5],[1.0,1.0])|\n",
      "|        6|Williams Henry|[williams, henry]|(20,[2,16],[1.0,1...|\n",
      "|        7|   Brown Grace|   [brown, grace]|(20,[6,17],[1.0,1...|\n",
      "|        8|   Smith Emily|   [smith, emily]|(20,[13,18],[1.0,...|\n",
      "|        9|   Smith Emily|   [smith, emily]|(20,[13,18],[1.0,...|\n",
      "|       10|   Brown Alice|   [brown, alice]|(20,[6,7],[1.0,1.0])|\n",
      "|       11|  Wilson Grace|  [wilson, grace]|(20,[12,17],[1.0,...|\n",
      "|       12| Johnson Frank| [johnson, frank]|(20,[1,15],[1.0,1...|\n",
      "|       13|  Miller Henry|  [miller, henry]|(20,[2,5],[1.0,1.0])|\n",
      "|       14|   Moore Frank|   [moore, frank]|(20,[1,3],[1.0,1.0])|\n",
      "|       15|Williams Grace|[williams, grace]|(20,[16,17],[1.0,...|\n",
      "|       16| Jones Charlie| [jones, charlie]|(20,[0,4],[1.0,1.0])|\n",
      "|       17|   Davis Henry|   [davis, henry]|(20,[2,14],[1.0,1...|\n",
      "|       18| Moore Charlie| [moore, charlie]|(20,[3,4],[1.0,1.0])|\n",
      "|       19|Williams David|[williams, david]|(20,[8,16],[1.0,1...|\n",
      "+---------+--------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer to convert the text data into a sparse matrix of term frequencies\n",
    "cv = CountVectorizer(inputCol=\"fname_tokenized\", outputCol=\"fname_features\")\n",
    "cv_model = cv.fit(words_df)\n",
    "features_df = cv_model.transform(words_df)\n",
    "\n",
    "features_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise string similarity\n",
    "string_sim = StringSimilarity(inputCol=\"text\", referenceCol=\"text\", outputCol=\"similarity\", metricName=\"jaccard\")\n",
    "similarity_df = string_sim.transform(df)\n",
    "\n",
    "# Normalize the similarity scores\n",
    "normalizer = Normalizer(inputCol=\"similarity\", outputCol=\"norm\")\n",
    "similarity_norm_df = normalizer.transform(similarity_df)\n",
    "\n",
    "# Assemble the normalized similarity scores into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"norm\"], outputCol=\"features\")\n",
    "feature_df = assembler.transform(similarity_norm_df)\n",
    "\n",
    "# Apply k-means clustering to the transformed data\n",
    "kmeans = KMeans(k=2, seed=1)\n",
    "model = kmeans.fit(feature_df)\n",
    "predictions = model.transform(feature_df)\n",
    "\n",
    "# Show the cluster number for each text string\n",
    "predictions.select(\"id\", \"text\", \"prediction\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "291a77f4c89d03a6a06fb3cfdc38f3e9d96eaade7a041e3cf8a7ec8edd79bfd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
